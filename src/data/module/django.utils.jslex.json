{
  "functions": [
    {
      "name": "literals",
      "params": [
        {
          "prefix": "",
          "name": "choices",
          "annotation": null
        },
        {
          "prefix": "",
          "name": "prefix",
          "annotation": null
        },
        {
          "prefix": "",
          "name": "suffix",
          "annotation": null
        }
      ],
      "docstring": "\"\"\"\n    Create a regex from a space-separated list of literal `choices`.\n\n    If provided, `prefix` and `suffix` will be attached to each choice\n    individually.\n    \"\"\""
    },
    {
      "name": "prepare_js_for_gettext",
      "params": [
        {
          "prefix": "",
          "name": "js",
          "annotation": null
        }
      ],
      "docstring": "\"\"\"\n    Convert the JavaScript source `js` into something resembling C for\n    xgettext.\n\n    What actually happens is that all the regex literals are replaced with\n    \"REGEX\".\n    \"\"\""
    }
  ],
  "classes": [
    {
      "name": "Tok",
      "methods": [],
      "classes": [],
      "docstring": "\"\"\"\n    A specification for a token class.\n    \"\"\""
    },
    {
      "name": "Lexer",
      "methods": [
        {
          "name": "lex",
          "params": [
            {
              "prefix": "",
              "name": "self",
              "annotation": null
            },
            {
              "prefix": "",
              "name": "text",
              "annotation": null
            }
          ],
          "docstring": "\"\"\"\n        Lexically analyze `text`.\n\n        Yield pairs (`name`, `tokentext`).\n        \"\"\""
        }
      ],
      "classes": [],
      "docstring": "\"\"\"\n    A generic multi-state regex-based lexer.\n    \"\"\""
    },
    {
      "name": "JsLexer",
      "methods": [],
      "classes": [],
      "docstring": "\"\"\"\n    A JavaScript lexer\n\n    >>> lexer = JsLexer()\n    >>> list(lexer.lex(\"a = 1\"))\n    [('id', 'a'), ('ws', ' '), ('punct', '='), ('ws', ' '), ('dnum', '1')]\n\n    This doesn't properly handle non-ASCII characters in the JavaScript source.\n    \"\"\""
    }
  ],
  "docstring": "\"\"\"JsLex: a lexer for JavaScript\"\"\""
}